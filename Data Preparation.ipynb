{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "\n",
    "walmart_data = pd.read_csv(r\"D:\\Woodpecker2024\\Walmart Data Analysis and Forcasting.csv\")\n",
    "calendar_data = pd.read_csv(r\"D:\\Woodpecker2024\\calendar.csv\")\n",
    "sales_data = pd.read_csv(r\"D:\\Woodpecker2024\\sales_train_validation.csv\")\n",
    "prices_data = pd.read_csv(r\"D:\\Woodpecker2024\\sell_prices.csv\")\n",
    "sample_data = pd.read_csv(r\"D:\\Woodpecker2024\\sample_submission.csv\")\n",
    "sales_eval_data = pd.read_csv(r\"D:\\Woodpecker2024\\sales_train_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6435, 8) \n",
      "\n",
      "(1969, 14) \n",
      "\n",
      "(30490, 1919) \n",
      "\n",
      "(6841121, 4) \n",
      "\n",
      "(60980, 29) \n",
      "\n",
      "(30490, 1947) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------UNDERSTANDING DATASET---------------\n",
    "#Checking rows and colums\n",
    "print(walmart_data.shape,'\\n')\n",
    "print(calendar_data.shape,'\\n')\n",
    "print(sales_data.shape,'\\n')\n",
    "print(prices_data.shape,'\\n')\n",
    "print(sample_data.shape,'\\n')\n",
    "print(sales_eval_data.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart Data:\n",
      "    Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
      "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n",
      "Calendar Data:\n",
      "          date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
      "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
      "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
      "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
      "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
      "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
      "\n",
      "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
      "0          NaN          NaN          NaN        0        0        0  \n",
      "1          NaN          NaN          NaN        0        0        0  \n",
      "2          NaN          NaN          NaN        0        0        0  \n",
      "3          NaN          NaN          NaN        1        1        0  \n",
      "4          NaN          NaN          NaN        1        0        1  \n",
      "Sales Data:\n",
      "                               id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
      "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
      "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
      "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
      "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
      "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
      "\n",
      "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
      "0       1       3       0       1       1  \n",
      "1       1       0       0       0       0  \n",
      "2       1       0       1       1       1  \n",
      "3       0       1       3       7       2  \n",
      "4       1       2       2       2       4  \n",
      "\n",
      "[5 rows x 1919 columns]\n",
      "Prices Data:\n",
      "   store_id        item_id  wm_yr_wk  sell_price\n",
      "0     CA_1  HOBBIES_1_001     11325        9.58\n",
      "1     CA_1  HOBBIES_1_001     11326        9.58\n",
      "2     CA_1  HOBBIES_1_001     11327        8.26\n",
      "3     CA_1  HOBBIES_1_001     11328        8.26\n",
      "4     CA_1  HOBBIES_1_001     11329        8.26\n",
      "Sample Data:\n",
      "                               id  F1  F2  F3  F4  F5  F6  F7  F8  F9  ...  \\\n",
      "0  HOBBIES_1_001_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
      "1  HOBBIES_1_002_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
      "2  HOBBIES_1_003_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
      "3  HOBBIES_1_004_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
      "4  HOBBIES_1_005_CA_1_validation   0   0   0   0   0   0   0   0   0  ...   \n",
      "\n",
      "   F19  F20  F21  F22  F23  F24  F25  F26  F27  F28  \n",
      "0    0    0    0    0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Sales Eval Data:\n",
      "                               id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
      "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
      "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
      "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
      "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
      "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
      "\n",
      "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
      "0       0       3       3       0       1  \n",
      "1       0       0       0       0       0  \n",
      "2       0       2       3       0       1  \n",
      "3       1       3       0       2       6  \n",
      "4       0       0       2       1       0  \n",
      "\n",
      "[5 rows x 1947 columns]\n"
     ]
    }
   ],
   "source": [
    "#Previewing the data\n",
    "print(\"Walmart Data:\\n\", walmart_data.head())\n",
    "print(\"Calendar Data:\\n\",calendar_data.head())\n",
    "print(\"Sales Data:\\n\",sales_data.head())\n",
    "print(\"Prices Data:\\n\",prices_data.head())\n",
    "print(\"Sample Data:\\n\",sample_data.head())\n",
    "print(\"Sales Eval Data:\\n\",sales_eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store             int64\n",
      "Date             object\n",
      "Weekly_Sales    float64\n",
      "Holiday_Flag      int64\n",
      "Temperature     float64\n",
      "Fuel_Price      float64\n",
      "CPI             float64\n",
      "Unemployment    float64\n",
      "dtype: object \n",
      "\n",
      "date            object\n",
      "wm_yr_wk         int64\n",
      "weekday         object\n",
      "wday             int64\n",
      "month            int64\n",
      "year             int64\n",
      "d               object\n",
      "event_name_1    object\n",
      "event_type_1    object\n",
      "event_name_2    object\n",
      "event_type_2    object\n",
      "snap_CA          int64\n",
      "snap_TX          int64\n",
      "snap_WI          int64\n",
      "dtype: object \n",
      "\n",
      "id          object\n",
      "item_id     object\n",
      "dept_id     object\n",
      "cat_id      object\n",
      "store_id    object\n",
      "             ...  \n",
      "d_1909       int64\n",
      "d_1910       int64\n",
      "d_1911       int64\n",
      "d_1912       int64\n",
      "d_1913       int64\n",
      "Length: 1919, dtype: object \n",
      "\n",
      "store_id       object\n",
      "item_id        object\n",
      "wm_yr_wk        int64\n",
      "sell_price    float64\n",
      "dtype: object \n",
      "\n",
      "id     object\n",
      "F1      int64\n",
      "F2      int64\n",
      "F3      int64\n",
      "F4      int64\n",
      "F5      int64\n",
      "F6      int64\n",
      "F7      int64\n",
      "F8      int64\n",
      "F9      int64\n",
      "F10     int64\n",
      "F11     int64\n",
      "F12     int64\n",
      "F13     int64\n",
      "F14     int64\n",
      "F15     int64\n",
      "F16     int64\n",
      "F17     int64\n",
      "F18     int64\n",
      "F19     int64\n",
      "F20     int64\n",
      "F21     int64\n",
      "F22     int64\n",
      "F23     int64\n",
      "F24     int64\n",
      "F25     int64\n",
      "F26     int64\n",
      "F27     int64\n",
      "F28     int64\n",
      "dtype: object \n",
      "\n",
      "id          object\n",
      "item_id     object\n",
      "dept_id     object\n",
      "cat_id      object\n",
      "store_id    object\n",
      "             ...  \n",
      "d_1937       int64\n",
      "d_1938       int64\n",
      "d_1939       int64\n",
      "d_1940       int64\n",
      "d_1941       int64\n",
      "Length: 1947, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking datatypes\n",
    "print(walmart_data.dtypes,'\\n')\n",
    "print(calendar_data.dtypes,'\\n')\n",
    "print(sales_data.dtypes,'\\n')\n",
    "print(prices_data.dtypes,'\\n')\n",
    "print(sample_data.dtypes,'\\n')\n",
    "print(sales_eval_data.dtypes,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Store  Weekly_Sales  Holiday_Flag  Temperature   Fuel_Price  \\\n",
      "count  6435.000000  6.435000e+03   6435.000000  6435.000000  6435.000000   \n",
      "mean     23.000000  1.046965e+06      0.069930    60.663782     3.358607   \n",
      "std      12.988182  5.643666e+05      0.255049    18.444933     0.459020   \n",
      "min       1.000000  2.099862e+05      0.000000    -2.060000     2.472000   \n",
      "25%      12.000000  5.533501e+05      0.000000    47.460000     2.933000   \n",
      "50%      23.000000  9.607460e+05      0.000000    62.670000     3.445000   \n",
      "75%      34.000000  1.420159e+06      0.000000    74.940000     3.735000   \n",
      "max      45.000000  3.818686e+06      1.000000   100.140000     4.468000   \n",
      "\n",
      "               CPI  Unemployment  \n",
      "count  6435.000000   6435.000000  \n",
      "mean    171.578394      7.999151  \n",
      "std      39.356712      1.875885  \n",
      "min     126.064000      3.879000  \n",
      "25%     131.735000      6.891000  \n",
      "50%     182.616521      7.874000  \n",
      "75%     212.743293      8.622000  \n",
      "max     227.232807     14.313000  \n",
      "           wm_yr_wk         wday        month         year      snap_CA  \\\n",
      "count   1969.000000  1969.000000  1969.000000  1969.000000  1969.000000   \n",
      "mean   11347.086338     3.997461     6.325546  2013.288471     0.330117   \n",
      "std      155.277043     2.001141     3.416864     1.580198     0.470374   \n",
      "min    11101.000000     1.000000     1.000000  2011.000000     0.000000   \n",
      "25%    11219.000000     2.000000     3.000000  2012.000000     0.000000   \n",
      "50%    11337.000000     4.000000     6.000000  2013.000000     0.000000   \n",
      "75%    11502.000000     6.000000     9.000000  2015.000000     1.000000   \n",
      "max    11621.000000     7.000000    12.000000  2016.000000     1.000000   \n",
      "\n",
      "           snap_TX      snap_WI  \n",
      "count  1969.000000  1969.000000  \n",
      "mean      0.330117     0.330117  \n",
      "std       0.470374     0.470374  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       1.000000     1.000000  \n",
      "max       1.000000     1.000000  \n",
      "                d_1           d_2           d_3           d_4           d_5  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       1.070220      1.041292      0.780026      0.833454      0.627944   \n",
      "std        5.126689      5.365468      3.667454      4.415141      3.379344   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      360.000000    436.000000    207.000000    323.000000    296.000000   \n",
      "\n",
      "                d_6           d_7           d_8           d_9          d_10  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       0.958052      0.918662      1.244080      1.073663      0.838701   \n",
      "std        4.785947      5.059495      6.617729      5.917204      4.206199   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      314.000000    316.000000    370.000000    385.000000    353.000000   \n",
      "\n",
      "       ...        d_1904        d_1905        d_1906        d_1907  \\\n",
      "count  ...  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean   ...      1.370581      1.586159      1.693670      1.248245   \n",
      "std    ...      3.740017      4.097191      4.359809      3.276925   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      1.000000      2.000000      2.000000      1.000000   \n",
      "max    ...    129.000000    160.000000    204.000000     98.000000   \n",
      "\n",
      "             d_1908        d_1909        d_1910        d_1911        d_1912  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       1.232207      1.159167      1.149000      1.328862      1.605838   \n",
      "std        3.125471      2.876026      2.950364      3.358012      4.089422   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        1.000000      1.000000      1.000000      1.000000      2.000000   \n",
      "max      100.000000     88.000000     77.000000    141.000000    171.000000   \n",
      "\n",
      "             d_1913  \n",
      "count  30490.000000  \n",
      "mean       1.633158  \n",
      "std        3.812248  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        2.000000  \n",
      "max      130.000000  \n",
      "\n",
      "[8 rows x 1913 columns]\n",
      "           wm_yr_wk    sell_price\n",
      "count  6.841121e+06  6.841121e+06\n",
      "mean   1.138294e+04  4.410952e+00\n",
      "std    1.486100e+02  3.408814e+00\n",
      "min    1.110100e+04  1.000000e-02\n",
      "25%    1.124700e+04  2.180000e+00\n",
      "50%    1.141100e+04  3.470000e+00\n",
      "75%    1.151700e+04  5.840000e+00\n",
      "max    1.162100e+04  1.073200e+02\n",
      "            F1       F2       F3       F4       F5       F6       F7       F8  \\\n",
      "count  60980.0  60980.0  60980.0  60980.0  60980.0  60980.0  60980.0  60980.0   \n",
      "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "            F9      F10  ...      F19      F20      F21      F22      F23  \\\n",
      "count  60980.0  60980.0  ...  60980.0  60980.0  60980.0  60980.0  60980.0   \n",
      "mean       0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "std        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "min        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "25%        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "50%        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "75%        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "max        0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "           F24      F25      F26      F27      F28  \n",
      "count  60980.0  60980.0  60980.0  60980.0  60980.0  \n",
      "mean       0.0      0.0      0.0      0.0      0.0  \n",
      "std        0.0      0.0      0.0      0.0      0.0  \n",
      "min        0.0      0.0      0.0      0.0      0.0  \n",
      "25%        0.0      0.0      0.0      0.0      0.0  \n",
      "50%        0.0      0.0      0.0      0.0      0.0  \n",
      "75%        0.0      0.0      0.0      0.0      0.0  \n",
      "max        0.0      0.0      0.0      0.0      0.0  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "                d_1           d_2           d_3           d_4           d_5  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       1.070220      1.041292      0.780026      0.833454      0.627944   \n",
      "std        5.126689      5.365468      3.667454      4.415141      3.379344   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      360.000000    436.000000    207.000000    323.000000    296.000000   \n",
      "\n",
      "                d_6           d_7           d_8           d_9          d_10  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       0.958052      0.918662      1.244080      1.073663      0.838701   \n",
      "std        4.785947      5.059495      6.617729      5.917204      4.206199   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      314.000000    316.000000    370.000000    385.000000    353.000000   \n",
      "\n",
      "       ...        d_1932        d_1933        d_1934        d_1935  \\\n",
      "count  ...  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean   ...      1.445490      1.781174      1.965267      1.389374   \n",
      "std    ...      3.656824      4.426550      4.706284      3.313292   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      1.000000      1.000000      0.000000   \n",
      "75%    ...      2.000000      2.000000      2.000000      2.000000   \n",
      "max    ...    143.000000    156.000000    187.000000     98.000000   \n",
      "\n",
      "             d_1936        d_1937        d_1938        d_1939        d_1940  \\\n",
      "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
      "mean       1.271794      1.216661      1.212299      1.395605      1.689669   \n",
      "std        3.126178      3.000348      2.955910      3.514318      4.089208   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
      "75%        1.000000      1.000000      1.000000      1.000000      2.000000   \n",
      "max       90.000000     77.000000     84.000000    110.000000    156.000000   \n",
      "\n",
      "             d_1941  \n",
      "count  30490.000000  \n",
      "mean       1.782158  \n",
      "std        4.284356  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        2.000000  \n",
      "max      117.000000  \n",
      "\n",
      "[8 rows x 1941 columns]\n"
     ]
    }
   ],
   "source": [
    "#Summary\n",
    "print(walmart_data.describe())\n",
    "print(calendar_data.describe())\n",
    "print(sales_data.describe())\n",
    "print(prices_data.describe())\n",
    "print(sample_data.describe())\n",
    "print(sales_eval_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store           0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "Holiday_Flag    0\n",
      "Temperature     0\n",
      "Fuel_Price      0\n",
      "CPI             0\n",
      "Unemployment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#-----------------DATA CLEANING------------\n",
    "#Handking missing values\n",
    "#1.1 Wallmart Dataset\n",
    "print(walmart_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               0\n",
      "wm_yr_wk           0\n",
      "weekday            0\n",
      "wday               0\n",
      "month              0\n",
      "year               0\n",
      "d                  0\n",
      "event_name_1    1807\n",
      "event_type_1    1807\n",
      "event_name_2    1964\n",
      "event_type_2    1964\n",
      "snap_CA            0\n",
      "snap_TX            0\n",
      "snap_WI            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.2 Calendar Dataset\n",
    "print(calendar_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with missing values: 99.75%\n"
     ]
    }
   ],
   "source": [
    "total_rows = calendar_data.shape[0]\n",
    "missing_rows = calendar_data[['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']].isna().any(axis=1).sum()\n",
    "percentage_missing = (missing_rows / total_rows) * 100\n",
    "\n",
    "print(f\"Percentage of rows with missing values: {percentage_missing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date            0\n",
      "wm_yr_wk        0\n",
      "weekday         0\n",
      "wday            0\n",
      "month           0\n",
      "year            0\n",
      "d               0\n",
      "event_name_1    0\n",
      "event_type_1    0\n",
      "event_name_2    0\n",
      "event_type_2    0\n",
      "snap_CA         0\n",
      "snap_TX         0\n",
      "snap_WI         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1886594961.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calendar_data['event_name_1'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1886594961.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calendar_data['event_type_1'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1886594961.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calendar_data['event_name_2'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1886594961.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calendar_data['event_type_2'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "calendar_data['event_name_1'].fillna('Unknown', inplace=True)\n",
    "calendar_data['event_type_1'].fillna('Unknown', inplace=True)\n",
    "calendar_data['event_name_2'].fillna('Unknown', inplace=True)\n",
    "calendar_data['event_type_2'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(calendar_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "item_id     0\n",
      "dept_id     0\n",
      "cat_id      0\n",
      "store_id    0\n",
      "           ..\n",
      "d_1909      0\n",
      "d_1910      0\n",
      "d_1911      0\n",
      "d_1912      0\n",
      "d_1913      0\n",
      "Length: 1919, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.3 Sales Data\n",
    "print(sales_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_id      0\n",
      "item_id       0\n",
      "wm_yr_wk      0\n",
      "sell_price    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.4 Prices Dataset\n",
    "print(prices_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\68634119.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  prices_data['sell_price'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\68634119.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  prices_data['sell_price'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "prices_data['sell_price'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1671468357.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  prices_data['wm_yr_wk'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_16000\\1671468357.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  prices_data['wm_yr_wk'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "prices_data.dropna(subset=['wm_yr_wk'])\n",
    "prices_data['wm_yr_wk'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id     0\n",
      "F1     0\n",
      "F2     0\n",
      "F3     0\n",
      "F4     0\n",
      "F5     0\n",
      "F6     0\n",
      "F7     0\n",
      "F8     0\n",
      "F9     0\n",
      "F10    0\n",
      "F11    0\n",
      "F12    0\n",
      "F13    0\n",
      "F14    0\n",
      "F15    0\n",
      "F16    0\n",
      "F17    0\n",
      "F18    0\n",
      "F19    0\n",
      "F20    0\n",
      "F21    0\n",
      "F22    0\n",
      "F23    0\n",
      "F24    0\n",
      "F25    0\n",
      "F26    0\n",
      "F27    0\n",
      "F28    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.5 Sample Dataset\n",
    "print(sample_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "item_id     0\n",
      "dept_id     0\n",
      "cat_id      0\n",
      "store_id    0\n",
      "           ..\n",
      "d_1937      0\n",
      "d_1938      0\n",
      "d_1939      0\n",
      "d_1940      0\n",
      "d_1941      0\n",
      "Length: 1947, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.6 Sales Evaluation Dataset\n",
    "print(sales_eval_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_eval_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 -----------------------Removing Duplicates-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n",
      "\n",
      "Calendar Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n",
      "\n",
      "Sales Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n",
      "\n",
      "Prices Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n",
      "\n",
      "Sample Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n",
      "\n",
      "Sales Evaluation Data Duplicates:\n",
      "Rows: 0\n",
      "Columns: []\n"
     ]
    }
   ],
   "source": [
    "#2.1 Walmart Data\n",
    "print(\"Walmart Data Duplicates:\")\n",
    "print(f\"Rows: {walmart_data[walmart_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {walmart_data.columns[walmart_data.columns.duplicated()].tolist()}\")\n",
    "\n",
    "#2.2 Calendar Data\n",
    "print(\"\\nCalendar Data Duplicates:\")\n",
    "print(f\"Rows: {calendar_data[calendar_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {calendar_data.columns[calendar_data.columns.duplicated()].tolist()}\")\n",
    "\n",
    "#2.3 Sales Data\n",
    "print(\"\\nSales Data Duplicates:\")\n",
    "print(f\"Rows: {sales_data[sales_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {sales_data.columns[sales_data.columns.duplicated()].tolist()}\")\n",
    "\n",
    "#2.4 Prices Data\n",
    "print(\"\\nPrices Data Duplicates:\")\n",
    "print(f\"Rows: {prices_data[prices_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {prices_data.columns[prices_data.columns.duplicated()].tolist()}\")\n",
    "\n",
    "#2.5 Sample Data\n",
    "print(\"\\nSample Data Duplicates:\")\n",
    "print(f\"Rows: {sample_data[sample_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {sample_data.columns[sample_data.columns.duplicated()].tolist()}\")\n",
    "\n",
    "#2.6 Sales Evaluation Data\n",
    "print(\"\\nSales Evaluation Data Duplicates:\")\n",
    "print(f\"Rows: {sales_eval_data[sales_eval_data.duplicated()].shape[0]}\")\n",
    "print(f\"Columns: {sales_eval_data.columns[sales_eval_data.columns.duplicated()].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Data Preprocessing and Integration-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 Walmart Data\n",
    "#date to datetime format\n",
    "walmart_data['Date'] = pd.to_datetime(walmart_data['Date'], dayfirst=True)\n",
    "\n",
    "walmart_data.rename(columns={'Store': 'store_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  wm_yr_wk\n",
      "0 2011-01-29     11101\n",
      "1 2011-01-30     11101\n",
      "2 2011-01-31     11101\n",
      "3 2011-02-01     11101\n",
      "4 2011-02-02     11101\n"
     ]
    }
   ],
   "source": [
    "#1.2 Calendar Data\n",
    "calendar_data['date'] = pd.to_datetime(calendar_data['date'])\n",
    "calendar_data = calendar_data[['date', 'wm_yr_wk']]\n",
    "columns_to_drop = ['event_name_2', 'event_type_2']\n",
    "calendar_data.drop(columns=[col for col in columns_to_drop if col in calendar_data.columns], inplace=True)\n",
    "\n",
    "print(calendar_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 Sales Data\n",
    "#restructured dataset\n",
    "sales_data_long = sales_data.melt(\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='day',\n",
    "    value_name='sales'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  sales  index       date  wm_yr_wk_x  wm_yr_wk_y  \n",
      "0       CA      0      1 2011-01-30       11101       11101  \n",
      "1       CA      0      1 2011-01-30       11101       11101  \n",
      "2       CA      0      1 2011-01-30       11101       11101  \n",
      "3       CA      0      1 2011-01-30       11101       11101  \n",
      "4       CA      0      1 2011-01-30       11101       11101  \n"
     ]
    }
   ],
   "source": [
    "#Sales and calendar\n",
    "sales_data_long['day'] = sales_data_long['day'].astype(str).str.replace('d_', '').astype(int)\n",
    "\n",
    "sales_data_long = sales_data_long.merge(calendar_data.reset_index(), left_on='day', right_index=True, how='left')\n",
    "sales_data_long = sales_data_long.merge(calendar_data, on='date', how='left')\n",
    "\n",
    "sales_data_long.drop(columns=['day'], inplace=True)\n",
    "print(sales_data_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'sales',\n",
      "       'index', 'date', 'wm_yr_wk_x', 'wm_yr_wk_y'],\n",
      "      dtype='object')\n",
      "Index(['store_id', 'item_id', 'wm_yr_wk', 'sell_price'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sales_data_long.columns)\n",
    "print(prices_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        wm_yr_wk_x  wm_yr_wk_y\n",
      "0            11101       11101\n",
      "182940       11102       11102\n",
      "396370       11103       11103\n",
      "609800       11104       11104\n",
      "823230       11105       11105\n"
     ]
    }
   ],
   "source": [
    "print(sales_data_long[['wm_yr_wk_x', 'wm_yr_wk_y']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_long.rename(columns={'wm_yr_wk_x': 'wm_yr_wk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  sales  index       date  wm_yr_wk  wm_yr_wk_y  sell_price  \n",
      "0       CA      0      1 2011-01-30     11101       11101         NaN  \n",
      "1       CA      0      1 2011-01-30     11101       11101         NaN  \n",
      "2       CA      0      1 2011-01-30     11101       11101         NaN  \n",
      "3       CA      0      1 2011-01-30     11101       11101         NaN  \n",
      "4       CA      0      1 2011-01-30     11101       11101         NaN  \n",
      "(58327370, 12)\n"
     ]
    }
   ],
   "source": [
    "# Merging prices and sales_data_long\n",
    "merged_data = sales_data_long.merge(prices_data, \n",
    "                                     on=['store_id', 'item_id', 'wm_yr_wk'], \n",
    "                                     how='left')\n",
    "\n",
    "print(merged_data.head())\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_id       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0         1 2010-02-05    1643690.90             0        42.31       2.572   \n",
      "1         1 2010-02-12    1641957.44             1        38.51       2.548   \n",
      "2         1 2010-02-19    1611968.17             0        39.93       2.514   \n",
      "3         1 2010-02-26    1409727.59             0        46.63       2.561   \n",
      "4         1 2010-03-05    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n",
      "Index(['store_id', 'Date', 'Weekly_Sales', 'Holiday_Flag', 'Temperature',\n",
      "       'Fuel_Price', 'CPI', 'Unemployment'],\n",
      "      dtype='object')\n",
      "id                    object\n",
      "item_id               object\n",
      "dept_id               object\n",
      "cat_id                object\n",
      "store_id              object\n",
      "state_id              object\n",
      "sales                  int64\n",
      "index                  int64\n",
      "date          datetime64[ns]\n",
      "wm_yr_wk               int64\n",
      "wm_yr_wk_y             int64\n",
      "sell_price           float64\n",
      "dtype: object\n",
      "store_id                 int64\n",
      "Date            datetime64[ns]\n",
      "Weekly_Sales           float64\n",
      "Holiday_Flag             int64\n",
      "Temperature            float64\n",
      "Fuel_Price             float64\n",
      "CPI                    float64\n",
      "Unemployment           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(walmart_data.head())\n",
    "print(walmart_data.columns)\n",
    "print(merged_data.dtypes)\n",
    "print(walmart_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA_1' 'CA_2' 'CA_3' 'CA_4' 'TX_1' 'TX_2' 'TX_3' 'WI_1' 'WI_2' 'WI_3']\n"
     ]
    }
   ],
   "source": [
    "print(merged_data['store_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_id                object\n",
      "Date            datetime64[ns]\n",
      "Weekly_Sales           float64\n",
      "Holiday_Flag             int64\n",
      "Temperature            float64\n",
      "Fuel_Price             float64\n",
      "CPI                    float64\n",
      "Unemployment           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "walmart_data['store_id'] = walmart_data['store_id'].astype(str)\n",
    "\n",
    "print(walmart_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging complete. Merged data saved to merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_in_chunks(df, chunk_size, func, *args, **kwargs):\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "    while start < len(df):\n",
    "        chunk = df.iloc[start:end]\n",
    "        func(chunk, *args, **kwargs)\n",
    "        start += chunk_size\n",
    "        end += chunk_size\n",
    "\n",
    "def merge_and_append(chunk, prices_data, output_path, header_written):\n",
    "    merged_chunk = chunk.merge(prices_data, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n",
    "    if not header_written[0]:\n",
    "        merged_chunk.to_csv(output_path, index=False)\n",
    "        header_written[0] = True\n",
    "    else:\n",
    "        merged_chunk.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "chunk_size = 100000 \n",
    "\n",
    "output_path = 'merged_data.csv'\n",
    "\n",
    "header_written = [False]\n",
    "\n",
    "process_in_chunks(sales_data_long, chunk_size, merge_and_append, prices_data, output_path, header_written)\n",
    "\n",
    "print(\"Merging complete. Merged data saved to\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_data_path = 'D:/Woodpecker2024/merged_data.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000 \n",
    "\n",
    "output_path = 'cleaned_merged_data.csv'\n",
    "\n",
    "header_written = False\n",
    "\n",
    "for chunk in pd.read_csv(merged_data_path, chunksize=chunk_size):\n",
    "    \n",
    "    cleaned_chunk = chunk.dropna()\n",
    "    \n",
    "    if not header_written:\n",
    "        cleaned_chunk.to_csv(output_path, index=False)\n",
    "        header_written = True\n",
    "    else:\n",
    "        cleaned_chunk.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = 100000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_merged_data222.csv\n"
     ]
    }
   ],
   "source": [
    "merged_data_path = 'D:/Woodpecker2024/cleaned_merged_data.csv'\n",
    "\n",
    "output_path = 'cleaned_merged_data222.csv'\n",
    "\n",
    "header_written = False\n",
    "\n",
    "for chunk in pd.read_csv(merged_data_path, chunksize=chunk_size):\n",
    "    \n",
    "    chunk = chunk.dropna()\n",
    "    \n",
    "    chunk = chunk.drop_duplicates()\n",
    "    \n",
    "    # Convert date column to datetime format\n",
    "    chunk['date'] = pd.to_datetime(chunk['date'], format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    # Ensure numerical columns have the correct type\n",
    "    chunk['sales'] = pd.to_numeric(chunk['sales'], errors='coerce')\n",
    "    chunk['index'] = pd.to_numeric(chunk['index'], errors='coerce')\n",
    "    chunk['sell_price'] = pd.to_numeric(chunk['sell_price'], errors='coerce')\n",
    "    \n",
    "    # Append the cleaned chunk to the output CSV file\n",
    "    if not header_written:\n",
    "        chunk.to_csv(output_path, index=False)\n",
    "        header_written = True\n",
    "    else:\n",
    "        chunk.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
